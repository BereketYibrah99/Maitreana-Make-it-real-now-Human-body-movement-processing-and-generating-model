{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a9d42e-f96a-4053-827b-623c734f8d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 11:12:30.928712: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1430/1430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.1155\n",
      "Epoch 2/3\n",
      "\u001b[1m1430/1430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0526\n",
      "Epoch 3/3\n",
      "\u001b[1m1430/1430\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.0465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "Generated samples shape: (5, 356)\n",
      "Sample data (first sample): [ 3.478313   -0.00759876  0.71235394 -0.35856748 -0.3304314  -0.3253756\n",
      " -1.8023881   0.99238604  2.1537256  -0.09488481  0.50220263 -0.29566836\n",
      " -0.2656945  -0.29924646 -1.4601655   1.0285158   1.7709928  -0.07546836\n",
      "  0.42515346 -0.2777443  -0.22112675 -0.28213775 -1.2700822   1.0037655\n",
      "  1.5476444  -0.11144415  0.3644592  -0.26855633 -0.20167167 -0.26689726\n",
      " -1.1270921   0.98767704  1.410085   -0.09194291  0.3444108  -0.2536827\n",
      " -0.17770547 -0.25152123 -1.0354369   0.97090113  1.2900827  -0.12244916\n",
      "  0.29794914 -0.26185483 -0.17873727 -0.2603454  -0.9701748   0.9453529\n",
      "  1.2112689  -0.11741716  0.29704893 -0.23617136 -0.14631009 -0.23246369\n",
      " -0.8932205   0.93430185  1.1429648  -0.10811397  0.27869004 -0.22678994\n",
      " -0.13658082 -0.23597941 -0.840661    0.9201855   1.0822029  -0.11743\n",
      "  0.2647385  -0.22100428 -0.12385696 -0.2238409  -0.78118366  0.9128218\n",
      "  1.0412943  -0.10908213  0.253211   -0.21825604 -0.11774883 -0.21880266\n",
      " -0.7526196   0.8978003   0.9939792  -0.12198347  0.24145508 -0.22456405\n",
      " -0.11049315 -0.20846964 -0.70690095  0.9012555   0.9680996  -0.11633462\n",
      "  0.23602898 -0.22853395 -0.1203572  -0.22517976 -0.6954931   0.8819954\n",
      "  0.9346231  -0.1113404   0.23464026 -0.21580385 -0.10969704 -0.21497709\n",
      " -0.67966616  0.8744835   0.9082407  -0.12122566  0.23279831 -0.21749708\n",
      " -0.10367858 -0.20892009 -0.64528334  0.8754935   0.8892335  -0.11030108\n",
      "  0.23504865 -0.20257267 -0.09027362 -0.19994086 -0.6185312   0.8725997\n",
      "  0.8623654  -0.11111364  0.22167839 -0.20531559 -0.08677295 -0.19208303\n",
      " -0.5942067   0.88111687  0.85980326 -0.10513939  0.21942021 -0.20485294\n",
      " -0.0823673  -0.19749507 -0.5716325   0.88318497  0.8423923  -0.1081126\n",
      "  0.22252434 -0.20478961 -0.07630929 -0.18830726 -0.55711627  0.88614833\n",
      "  0.8369566  -0.10769069  0.21563363 -0.2274252  -0.09403086 -0.20678464\n",
      " -0.56739986  0.88245994  0.8224627  -0.08849123  0.22432458 -0.19654381\n",
      " -0.07546887 -0.1967763  -0.54494995  0.8867149   0.8102326  -0.10535002\n",
      "  0.21138826 -0.21700616 -0.08546464 -0.21283318 -0.5679926   0.8725822\n",
      "  0.78105295 -0.11447889  0.20481932 -0.22170666 -0.07937106 -0.20243487\n",
      " -0.54365057  0.8906212   0.78623605 -0.11772189  0.20791247 -0.21383801\n",
      " -0.06928673 -0.19922611 -0.5297757   0.9060245   0.7848892  -0.12701568\n",
      "  0.2077401  -0.22892609 -0.08261791 -0.21063393 -0.5281805   0.91398704\n",
      "  0.7806955  -0.11061221  0.21288404 -0.21529058 -0.06160054 -0.19238201\n",
      " -0.50862384  0.94097996  0.7889039  -0.11459231  0.21547213 -0.21324578\n",
      " -0.05746207 -0.19049549 -0.5068084   0.9601953   0.7938144  -0.11648795\n",
      "  0.21174379 -0.21844783 -0.06229591 -0.21203324 -0.52485555  0.9632027\n",
      "  0.7752208  -0.14178401  0.19762644 -0.2509731  -0.07180798 -0.21815515\n",
      " -0.51197636  0.98441637  0.79316866 -0.13060239  0.21466273 -0.23864222\n",
      " -0.06243593 -0.2167311  -0.50686073  1.0104983   0.7950425  -0.13226354\n",
      "  0.21785778 -0.2399478  -0.06709012 -0.22817516 -0.5075252   1.0300556\n",
      "  0.7993536  -0.13611028  0.22899076 -0.22830755 -0.04730615 -0.21193033\n",
      " -0.48667598  1.0715995   0.81312    -0.14976197  0.2262393  -0.2562378\n",
      " -0.05063075 -0.22332165 -0.5052235   1.1034651   0.82268655 -0.14254338\n",
      "  0.23154774 -0.25410807 -0.04374385 -0.23042783 -0.48864582  1.1427858\n",
      "  0.8362552  -0.15446493  0.23443258 -0.26299253 -0.04932535 -0.23806167\n",
      " -0.5053798   1.1820977   0.8385186  -0.18041593  0.22994931 -0.28614607\n",
      " -0.05528641 -0.25118798 -0.5063019   1.2347684   0.85713917 -0.1899387\n",
      "  0.2254499  -0.31717074 -0.06146675 -0.26959848 -0.5214693   1.295713\n",
      "  0.8868699  -0.18822429  0.24319392 -0.31540832 -0.05711707 -0.28147495\n",
      " -0.5106257   1.3663023   0.9152242  -0.18825272  0.2589144  -0.33374244\n",
      " -0.04238251 -0.28688028 -0.52386045  1.4565202   0.95255196 -0.20144144\n",
      "  0.2857064  -0.33153722 -0.02259719 -0.28635767 -0.5234724   1.5626382\n",
      "  0.981342   -0.20901704  0.29784346 -0.35285476 -0.0151279  -0.3049431\n",
      " -0.5170687   1.6895118   1.0242523  -0.24584293  0.30668575 -0.3985113\n",
      " -0.01673087 -0.34193638 -0.5348501   1.853791    1.0647205  -0.29724506\n",
      "  0.3103617  -0.4487009  -0.01670504 -0.38082403 -0.5407332   2.0827234\n",
      "  1.1550268  -0.35111964  0.3306129  -0.5437534   0.00355625 -0.4325177\n",
      " -0.57006955  2.464227    1.2707226  -0.43542883  0.3668699  -0.674327\n",
      "  0.01936278 -0.5482335  -0.64227843  3.2861133   1.6180794  -0.7015925\n",
      "  0.4540063  -1.1694295 ]\n",
      "Min value in generated samples: -1.8781451\n",
      "Max value in generated samples: 3.5521817\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load data\n",
    "with open('param.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "# Reshape data to (n_samples, n_features)\n",
    "data = np.tile(np.array(data, dtype=np.float32), 108).reshape(-1, 356)\n",
    "\n",
    "# Manual normalization to [-1, 1] range (for tanh activation)\n",
    "def manual_normalize(data):\n",
    "    data_min = np.min(data, axis=0)\n",
    "    data_max = np.max(data, axis=0)\n",
    "    # Handle case where min == max to avoid division by zero\n",
    "    scale = np.where(data_max != data_min, 2.0 / (data_max - data_min), 1.0)\n",
    "    normalized = -1.0 + scale * (data - data_min)\n",
    "    return normalized, data_min, data_max\n",
    "\n",
    "def manual_denormalize(normalized_data, data_min, data_max):\n",
    "    # Inverse of manual_normalize\n",
    "    scale = np.where(data_max != data_min, 2.0 / (data_max - data_min), 1.0)\n",
    "    original = data_min + (normalized_data + 1.0) / scale\n",
    "    return original\n",
    "\n",
    "# Normalize data\n",
    "normalized_data, data_min, data_max = manual_normalize(data)\n",
    "\n",
    "# Parameters\n",
    "latent_dim = 100\n",
    "input_dim = normalized_data.shape[1]  # 89 features\n",
    "batch_size = 64\n",
    "epochs = 3\n",
    "patience = 5\n",
    "\n",
    "# Custom VAE loss layer\n",
    "class VAELossLayer(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x, z_mean, z_log_var, x_decoded = inputs\n",
    "        # Reconstruction loss\n",
    "        recon_loss = tf.reduce_mean(tf.square(x - x_decoded))\n",
    "        # KL divergence\n",
    "        kl_loss = -0.5 * tf.reduce_mean(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "        # Total loss\n",
    "        self.add_loss(recon_loss + kl_loss)\n",
    "        return x_decoded\n",
    "\n",
    "# Encoder\n",
    "def build_encoder():\n",
    "    inputs = layers.Input(shape=(input_dim,))\n",
    "    x = layers.Dense(256, activation='relu')(inputs)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    return Model(inputs, [z_mean, z_log_var], name=\"encoder\")\n",
    "\n",
    "# Sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Decoder\n",
    "def build_decoder():\n",
    "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(256, activation='relu')(latent_inputs)\n",
    "    outputs = layers.Dense(input_dim, activation='tanh')(x)\n",
    "    return Model(latent_inputs, outputs, name=\"decoder\")\n",
    "\n",
    "# Build VAE\n",
    "encoder = build_encoder()\n",
    "decoder = build_decoder()\n",
    "\n",
    "# Input layer\n",
    "inputs = layers.Input(shape=(input_dim,))\n",
    "# Get latent variables\n",
    "z_mean, z_log_var = encoder(inputs)\n",
    "# Sample from latent space\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "# Reconstruct input\n",
    "outputs = decoder(z)\n",
    "\n",
    "# Add VAE loss\n",
    "outputs = VAELossLayer()([inputs, z_mean, z_log_var, outputs])\n",
    "\n",
    "# Create VAE model\n",
    "vae = Model(inputs, outputs, name=\"vae\")\n",
    "\n",
    "# Compile VAE\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "vae.compile(optimizer=optimizer)\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=patience,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train VAE\n",
    "history = vae.fit(\n",
    "    normalized_data,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stopping],\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Generate samples\n",
    "def generate_samples(num_samples):\n",
    "    noise = tf.random.normal(shape=(num_samples, latent_dim))\n",
    "    generated_normalized = decoder.predict(noise)\n",
    "    generated = manual_denormalize(generated_normalized, data_min, data_max)\n",
    "    return generated\n",
    "\n",
    "# Save models\n",
    "encoder.save('vae_encoder.h5')\n",
    "decoder.save('vae_decoder.h5')\n",
    "vae.save('vae_model.h5')\n",
    "\n",
    "# Save normalization parameters\n",
    "np.savez('normalization_params.npz', data_min=data_min, data_max=data_max)\n",
    "\n",
    "# Generate and print some samples\n",
    "samples = generate_samples(5)\n",
    "print(\"Generated samples shape:\", samples.shape)\n",
    "print(\"Sample data (first sample):\", samples[0])\n",
    "print(\"Min value in generated samples:\", np.min(samples))\n",
    "print(\"Max value in generated samples:\", np.max(samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1bf075-c7fb-4f1e-b640-e4a256f50125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 5.83508759e+01, -1.48726654e+00,  1.86574707e+01, -4.08523560e-01,\n",
       "        1.10439091e+01, -3.20655823e-01,  8.08969307e+00,  4.39474106e-01,\n",
       "        5.63818169e+00, -1.29783630e-01,  4.69741821e+00,  6.36335373e-01,\n",
       "        4.76300621e+00,  2.67868042e-02,  4.28443527e+00, -1.59519196e-01,\n",
       "        3.37932777e+00,  2.66742706e-02,  2.97634411e+00, -3.62815857e-01,\n",
       "        2.69639492e+00, -1.19199753e-01,  2.41815662e+00,  2.81211853e-01,\n",
       "        2.79145432e+00,  2.40846634e-01,  2.27065468e+00,  9.01985168e-02,\n",
       "        2.30745316e+00,  2.52185822e-01,  1.72310066e+00,  1.38048172e-01,\n",
       "        2.00636959e+00, -9.98344421e-02,  1.32189178e+00,  3.95956039e-01,\n",
       "        1.38926125e+00,  4.05349731e-02,  9.96501923e-01, -2.99383163e-01,\n",
       "        1.87197304e+00,  2.47028351e-01,  1.24649239e+00,  2.59674072e-01,\n",
       "        1.87097645e+00,  4.45842743e-02,  1.76911068e+00, -1.75168991e-01,\n",
       "        1.24607658e+00, -1.54285431e-01,  1.10260201e+00, -6.72130585e-02,\n",
       "        1.41532993e+00,  1.66341782e-01,  1.29683208e+00,  3.21779251e-02,\n",
       "        1.35151768e+00,  1.18276596e-01,  1.51600266e+00, -2.81085968e-02,\n",
       "        7.88283348e-01, -1.54507637e-01,  1.00523758e+00, -5.53993225e-01,\n",
       "        1.45832634e+00, -2.73342133e-01,  1.27813435e+00,  3.31460953e-01,\n",
       "        1.18708038e+00, -7.18650818e-02,  1.27090836e+00, -7.34043121e-02,\n",
       "        1.10081482e+00, -1.41098976e-01,  1.44133282e+00,  1.96434021e-01,\n",
       "        1.09711075e+00,  5.99737167e-02,  5.94129562e-01, -6.93130493e-03,\n",
       "        1.23888206e+00,  3.15504074e-01,  1.10982704e+00, -1.70897484e-01,\n",
       "        9.17296410e-01, -3.34236145e-01,  1.47009563e+00, -1.96842194e-01,\n",
       "        8.68358612e-01,  1.93765030e+02, -4.88159180e-01,  6.43195038e+01,\n",
       "       -2.42811203e-01,  3.87763824e+01, -1.02069855e-01,  2.76985855e+01,\n",
       "       -1.33184433e-01,  2.15113277e+01, -5.17654419e-02,  1.77048035e+01,\n",
       "       -7.41815567e-02,  1.49777317e+01, -8.05578232e-02,  1.29843912e+01,\n",
       "       -6.02540970e-02,  1.14259834e+01, -2.51007080e-02,  1.03109512e+01,\n",
       "        1.61194801e-02,  9.39369106e+00, -4.41489220e-02,  8.59613419e+00,\n",
       "       -2.12168694e-02,  7.96366262e+00,  1.91736221e-03,  7.41753674e+00,\n",
       "       -1.99203491e-02,  6.92098475e+00, -4.04372215e-02,  6.52860546e+00,\n",
       "       -3.55315208e-03,  6.21375751e+00, -2.05838680e-02,  5.88839769e+00,\n",
       "       -5.53722382e-02,  5.58723497e+00, -2.93626785e-02,  5.35512543e+00,\n",
       "       -2.73399353e-02,  5.12994623e+00, -7.40985870e-02,  4.91106987e+00,\n",
       "       -5.15873432e-02,  4.77798414e+00,  8.75568390e-03,  4.60817575e+00,\n",
       "       -1.21192932e-02,  4.47584248e+00, -2.70137787e-02,  4.37393475e+00,\n",
       "        3.96013260e-04,  4.22722387e+00,  5.49554825e-03,  4.14761829e+00,\n",
       "        1.03795528e-03,  4.04569626e+00, -7.66468048e-03,  3.93028021e+00,\n",
       "        1.26087666e-02,  3.85477972e+00, -3.97014618e-03,  3.78505039e+00,\n",
       "        1.78480148e-02,  3.73382115e+00, -1.24821663e-02,  3.67648315e+00,\n",
       "       -2.37538815e-02,  3.61475849e+00, -4.05373573e-02,  3.56801081e+00,\n",
       "       -1.72033310e-02,  3.52953243e+00, -2.03328133e-02,  3.46563530e+00,\n",
       "        6.91676140e-03,  3.47512460e+00, -3.43675613e-02,  3.47616720e+00,\n",
       "       -2.58595943e-02,  3.44664931e+00, -8.99171829e-03,  3.44371915e+00,\n",
       "        2.85935402e-03,  3.41577196e+00,  1.96121931e-02,  3.42934990e+00,\n",
       "       -3.10909748e-03,  3.40482807e+00,  1.62737976e+02,  3.43656540e-03,\n",
       "        5.42306137e+01,  1.06439590e-02,  3.25591583e+01,  9.07588005e-03,\n",
       "        2.32966156e+01,  9.27996635e-03,  1.81527328e+01,  9.90402699e-03,\n",
       "        1.48856134e+01, -4.82010841e-03,  1.26165657e+01, -8.18645954e-03,\n",
       "        1.09738369e+01, -5.86056709e-03,  9.71941757e+00, -9.26876068e-03,\n",
       "        8.72749138e+00,  2.28714943e-03,  7.93285561e+00,  4.66084480e-03,\n",
       "        7.26434708e+00, -5.88941574e-03,  6.72015667e+00, -2.19523907e-04,\n",
       "        6.26126146e+00, -1.10805631e-02,  5.85619640e+00,  1.04802847e-03,\n",
       "        5.52147722e+00, -1.06370449e-03,  5.22176409e+00,  1.97815895e-03,\n",
       "        4.95093441e+00,  1.23730898e-02,  4.73153305e+00, -2.29644775e-03,\n",
       "        4.51416492e+00,  4.88543510e-03,  4.33746195e+00,  1.97109580e-03,\n",
       "        4.17538309e+00, -3.94698977e-03,  4.02609348e+00, -3.37964296e-03,\n",
       "        3.89305639e+00, -8.11487436e-04,  3.77255297e+00, -1.05045736e-02,\n",
       "        3.66370106e+00,  3.56620550e-03,  3.57061863e+00, -3.56385112e-03,\n",
       "        3.47870612e+00, -1.00994110e-03,  3.39420271e+00, -6.79630041e-03,\n",
       "        3.32451582e+00,  6.67333603e-04,  3.25993800e+00, -5.71238995e-03,\n",
       "        3.20014715e+00, -2.13634968e-03,  3.15095735e+00, -5.37666678e-03,\n",
       "        3.10062361e+00,  4.47469950e-03,  3.06585407e+00,  5.11357188e-03,\n",
       "        3.02249289e+00, -2.20930576e-03,  2.98756981e+00, -2.12806463e-03,\n",
       "        2.95799780e+00,  9.22918320e-04,  2.93808222e+00,  9.76324081e-04,\n",
       "        2.91673899e+00,  5.68008423e-03,  2.89649439e+00,  5.30335307e-03,\n",
       "        2.88768339e+00,  2.64808536e-03,  2.87967348e+00,  2.30211020e-03,\n",
       "        2.86931992e+00,  3.39451432e-03,  2.86665916e+00,  1.65191513e+02,\n",
       "        4.54206467e-02,  5.50979805e+01,  6.65755272e-02,  3.30849724e+01,\n",
       "        4.55379486e-02,  2.36953430e+01, -4.25910950e-03,  1.84755898e+01,\n",
       "       -3.02886963e-03,  1.50909348e+01,  5.18417358e-02,  1.28411217e+01,\n",
       "        3.78684998e-02,  1.10994263e+01,  3.85198593e-02,  9.80292988e+00,\n",
       "        1.35064125e-02,  8.83211136e+00,  3.17668915e-03,  8.04335594e+00,\n",
       "        2.32896805e-02,  7.40131235e+00,  1.56250000e-02,  6.80595970e+00,\n",
       "        2.60472298e-02,  6.33080006e+00,  2.50213146e-02,  5.89177895e+00,\n",
       "        9.20772552e-03,  5.61043119e+00,  1.38874054e-02,  5.23093796e+00,\n",
       "       -3.49998474e-03,  5.00696516e+00, -4.13799286e-03,  4.76423311e+00,\n",
       "       -1.01752281e-02,  4.55245209e+00,  1.04570389e-03,  4.37729692e+00,\n",
       "       -2.95844078e-02,  4.19093323e+00, -1.41587257e-02,  4.04831171e+00,\n",
       "       -1.41158104e-02,  3.90613699e+00, -1.05090141e-02,  3.80433345e+00,\n",
       "       -2.27599144e-02,  3.68682075e+00,  1.34623051e-02,  3.58394480e+00,\n",
       "       -1.02391243e-02,  3.49934506e+00, -1.16510391e-02,  3.43530655e+00,\n",
       "        1.14068985e-02,  3.35542965e+00,  2.40707397e-03,  3.26912665e+00,\n",
       "       -2.77209282e-03,  3.21786475e+00,  3.93247604e-03,  3.15786338e+00,\n",
       "        9.06538963e-03,  3.11799002e+00, -3.09872627e-03,  3.05567980e+00,\n",
       "        4.81057167e-03,  3.04110193e+00,  1.09040737e-02,  3.00033569e+00,\n",
       "        4.80413437e-03,  2.97035813e+00,  1.16693974e-02,  2.95596385e+00,\n",
       "       -7.35044479e-03,  2.93688250e+00,  2.04238892e-02,  2.92674303e+00,\n",
       "       -9.13643837e-03,  2.90188050e+00, -1.83773041e-03,  2.88601732e+00,\n",
       "       -1.17120743e-02,  2.89338374e+00, -1.41081810e-02,  2.88684320e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = generate_samples(5)\n",
    "\n",
    "print(len(samples))\n",
    "samples[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
